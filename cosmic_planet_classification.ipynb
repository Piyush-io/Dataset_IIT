{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cosmic Planet Classification\n",
    "\n",
    "This notebook implements a machine learning pipeline to classify planets based on their features using a combination of deep learning (TensorFlow), Random Forest, and XGBoost, followed by an ensemble prediction. The goal is to predict planet types from a dataset and generate a submission file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd #type: ignore\n",
    "import numpy as np #type: ignore\n",
    "import tensorflow as tf #type: ignore\n",
    "from sklearn.preprocessing import StandardScaler #type: ignore\n",
    "from sklearn.impute import KNNImputer #type: ignore\n",
    "from sklearn.model_selection import train_test_split #type: ignore\n",
    "from sklearn.metrics import accuracy_score #type: ignore\n",
    "import xgboost as xgb #type: ignore\n",
    "import lightgbm as lgb\n",
    "from tensorflow.keras.utils import to_categorical #type: ignore\n",
    "from tensorflow.keras.regularizers import l2 #type: ignore\n",
    "import os\n",
    "\n",
    "PLANET_TYPES = {\n",
    "    1: \"Bewohnbar\",\n",
    "    2: \"Terraformierbar\",\n",
    "    3: \"Rohstoffreich\",\n",
    "    4: \"Wissenschaftlich\",\n",
    "    5: \"Gasriese\",\n",
    "    6: \"Wüstenplanet\",\n",
    "    7: \"Eiswelt\",\n",
    "    8: \"Toxischetmosäre\",\n",
    "    9: \"Hohestrahlung\",\n",
    "    10: \"Toterahswelt\"\n",
    "}\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "imputer = KNNImputer(n_neighbors=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing Function\n",
    "\n",
    "This function loads and preprocesses the data, handling missing values, generating interaction features, and scaling numerical columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_preprocess_data(filepath, is_train=True, imputer=None, scaler=None, feature_cols=None):\n",
    "    df = pd.read_csv(filepath)\n",
    "    print(f\"\\nData loaded from {filepath}.\")\n",
    "    print(f\"Dataset dimensions: {df.shape[0]} rows, {df.shape[1]} columns\")\n",
    "\n",
    "    if is_train:\n",
    "        df = df[df['Prediction'] >= 0]\n",
    "\n",
    "    planet_ids = np.arange(len(df)) + 1\n",
    "\n",
    "    # Clean categorical features encoded as strings\n",
    "    for col in ['Magnetic Field Strength', 'Radiation Levels']:\n",
    "        if col in df.columns:\n",
    "            df[col] = df[col].apply(lambda x: float(str(x).replace('Category_', '')) if isinstance(x, str) and 'Category_' in x else np.nan)\n",
    "\n",
    "    # Handle missing values with KNN imputation\n",
    "    if is_train:\n",
    "        feature_cols = [col for col in df.columns if col != 'Prediction']\n",
    "        imputer = KNNImputer(n_neighbors=5)\n",
    "        X_imputed = pd.DataFrame(imputer.fit_transform(df[feature_cols]), columns=feature_cols, index=df.index)\n",
    "        df_imputed = X_imputed.join(df['Prediction'])\n",
    "    else:\n",
    "        X_imputed = pd.DataFrame(imputer.transform(df), columns=df.columns, index=df.index)\n",
    "        df_imputed = X_imputed\n",
    "\n",
    "    # Generate interaction features\n",
    "    if is_train:\n",
    "        feature_cols = [col for col in df_imputed.columns if col != 'Prediction']\n",
    "        for i, col1 in enumerate(feature_cols):\n",
    "            for col2 in feature_cols[i+1:]:\n",
    "                df_imputed[f'{col1}_{col2}_interaction'] = df_imputed[col1] * df_imputed[col2]\n",
    "    else:\n",
    "        for i, col1 in enumerate(feature_cols):\n",
    "            for col2 in feature_cols[i+1:]:\n",
    "                df_imputed[f'{col1}_{col2}_interaction'] = df_imputed[col1] * df_imputed[col2]\n",
    "\n",
    "    # Scale numerical features\n",
    "    numerical_cols = df_imputed.select_dtypes(include=['float64', 'int64']).columns.tolist()\n",
    "    if 'Prediction' in numerical_cols:\n",
    "        numerical_cols.remove('Prediction')\n",
    "\n",
    "    if is_train:\n",
    "        scaler = StandardScaler()\n",
    "        df_imputed[numerical_cols] = scaler.fit_transform(df_imputed[numerical_cols])\n",
    "    else:\n",
    "        df_imputed[numerical_cols] = scaler.transform(df_imputed[numerical_cols])\n",
    "\n",
    "    if is_train:\n",
    "        return df_imputed, imputer, scaler, feature_cols, planet_ids\n",
    "    else:\n",
    "        return df_imputed, planet_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Learning Model\n",
    "\n",
    "Define a deep neural network with skip connections, batch normalization, and dropout for regularization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_deep_model(input_shape):\n",
    "    inputs = tf.keras.Input(shape=input_shape)\n",
    "    \n",
    "    # Add Gaussian noise to handle data noise\n",
    "    x = layers.GaussianNoise(stddev=0.01)(inputs)\n",
    "    \n",
    "    # First hidden layer\n",
    "    x = layers.Dense(256, kernel_regularizer=regularizers.l2(0.001))(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ELU(alpha=0.1)(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    \n",
    "    # Second hidden layer\n",
    "    x = layers.Dense(128, kernel_regularizer=regularizers.l2(0.001))(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ELU(alpha=0.1)(x)\n",
    "    x = layers.Dropout(0.2)(x)\n",
    "    \n",
    "    # Third hidden layer\n",
    "    x = layers.Dense(64, kernel_regularizer=regularizers.l2(0.001))(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ELU(alpha=0.1)(x)\n",
    "    x = layers.Dropout(0.1)(x)\n",
    "    \n",
    "    # Output layer\n",
    "    outputs = layers.Dense(10, activation='softmax')(x)\n",
    "    \n",
    "    # Compile the model\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.AdamW(learning_rate=0.001, weight_decay=0.001),\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation and Training Functions\n",
    "\n",
    "Functions to evaluate models and train classifiers (Neural Network, Random Forest, XGBoost)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(y_true, y_pred, model_name=\"Neural Network\"):\n",
    "    y_true_classes = np.argmax(y_true, axis=1)\n",
    "    y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "    accuracy = accuracy_score(y_true_classes, y_pred_classes)\n",
    "    print(f'\\n{model_name} Performance Metrics:')\n",
    "    print(f'Accuracy: {accuracy:.4f}')\n",
    "    print(\"\\nSample Predictions (first 5):\")\n",
    "    for true_val, pred_val in zip(y_true_classes[:5], y_pred_classes[:5]):\n",
    "        print(f'True: {PLANET_TYPES[true_val + 1]}, Predicted: {PLANET_TYPES[pred_val + 1]}')\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble Prediction\n",
    "\n",
    "Combine predictions from all models using a weighted ensemble approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Execution\n",
    "\n",
    "The main function orchestrates the entire pipeline: loading data, training models, evaluating performance, and generating predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting Cosmic Planet Classification with Neural Network...\n",
      "\n",
      "Data loaded from train/train.csv.\n",
      "Dataset dimensions: 60000 rows, 11 columns\n",
      "Removed 16 highly correlated features\n",
      "Epoch 1/150\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6622 - loss: 1.3992 - val_accuracy: 0.8783 - val_loss: 0.6534 - learning_rate: 5.0000e-04\n",
      "Epoch 2/150\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8447 - loss: 0.7449 - val_accuracy: 0.8904 - val_loss: 0.5530 - learning_rate: 5.0000e-04\n",
      "Epoch 3/150\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8606 - loss: 0.6420 - val_accuracy: 0.8969 - val_loss: 0.4906 - learning_rate: 5.0000e-04\n",
      "Epoch 4/150\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8704 - loss: 0.5731 - val_accuracy: 0.9016 - val_loss: 0.4471 - learning_rate: 5.0000e-04\n",
      "Epoch 5/150\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8768 - loss: 0.5290 - val_accuracy: 0.9042 - val_loss: 0.4182 - learning_rate: 5.0000e-04\n",
      "Epoch 6/150\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8802 - loss: 0.4914 - val_accuracy: 0.9047 - val_loss: 0.4021 - learning_rate: 5.0000e-04\n",
      "Epoch 7/150\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8828 - loss: 0.4699 - val_accuracy: 0.9062 - val_loss: 0.3838 - learning_rate: 5.0000e-04\n",
      "Epoch 8/150\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8860 - loss: 0.4509 - val_accuracy: 0.9070 - val_loss: 0.3749 - learning_rate: 5.0000e-04\n",
      "Epoch 9/150\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8861 - loss: 0.4390 - val_accuracy: 0.9088 - val_loss: 0.3662 - learning_rate: 5.0000e-04\n",
      "Epoch 10/150\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8914 - loss: 0.4260 - val_accuracy: 0.9073 - val_loss: 0.3612 - learning_rate: 5.0000e-04\n",
      "Epoch 11/150\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8919 - loss: 0.4161 - val_accuracy: 0.9082 - val_loss: 0.3504 - learning_rate: 4.5000e-04\n",
      "Epoch 12/150\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8924 - loss: 0.4055 - val_accuracy: 0.9095 - val_loss: 0.3470 - learning_rate: 4.5000e-04\n",
      "Epoch 13/150\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8937 - loss: 0.3985 - val_accuracy: 0.9133 - val_loss: 0.3396 - learning_rate: 4.5000e-04\n",
      "Epoch 14/150\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8949 - loss: 0.3940 - val_accuracy: 0.9122 - val_loss: 0.3390 - learning_rate: 4.5000e-04\n",
      "Epoch 15/150\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8970 - loss: 0.3886 - val_accuracy: 0.9121 - val_loss: 0.3392 - learning_rate: 4.5000e-04\n",
      "Epoch 16/150\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8947 - loss: 0.3869 - val_accuracy: 0.9137 - val_loss: 0.3352 - learning_rate: 4.5000e-04\n",
      "Epoch 17/150\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8952 - loss: 0.3841 - val_accuracy: 0.9126 - val_loss: 0.3360 - learning_rate: 4.5000e-04\n",
      "Epoch 18/150\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9003 - loss: 0.3766 - val_accuracy: 0.9141 - val_loss: 0.3318 - learning_rate: 4.5000e-04\n",
      "Epoch 19/150\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8988 - loss: 0.3732 - val_accuracy: 0.9141 - val_loss: 0.3273 - learning_rate: 4.5000e-04\n",
      "Epoch 20/150\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8994 - loss: 0.3703 - val_accuracy: 0.9120 - val_loss: 0.3324 - learning_rate: 4.5000e-04\n",
      "Epoch 21/150\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9017 - loss: 0.3642 - val_accuracy: 0.9136 - val_loss: 0.3252 - learning_rate: 4.0500e-04\n",
      "Epoch 22/150\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8996 - loss: 0.3638 - val_accuracy: 0.9134 - val_loss: 0.3291 - learning_rate: 4.0500e-04\n",
      "Epoch 23/150\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9005 - loss: 0.3594 - val_accuracy: 0.9112 - val_loss: 0.3293 - learning_rate: 4.0500e-04\n",
      "Epoch 24/150\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9031 - loss: 0.3581 - val_accuracy: 0.9133 - val_loss: 0.3274 - learning_rate: 4.0500e-04\n",
      "Epoch 25/150\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9031 - loss: 0.3552 - val_accuracy: 0.9142 - val_loss: 0.3244 - learning_rate: 4.0500e-04\n",
      "Epoch 26/150\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9037 - loss: 0.3514 - val_accuracy: 0.9137 - val_loss: 0.3259 - learning_rate: 4.0500e-04\n",
      "Epoch 27/150\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9003 - loss: 0.3537 - val_accuracy: 0.9167 - val_loss: 0.3234 - learning_rate: 4.0500e-04\n",
      "Epoch 28/150\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9027 - loss: 0.3527 - val_accuracy: 0.9132 - val_loss: 0.3257 - learning_rate: 4.0500e-04\n",
      "Epoch 29/150\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9014 - loss: 0.3549 - val_accuracy: 0.9145 - val_loss: 0.3218 - learning_rate: 4.0500e-04\n",
      "Epoch 30/150\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9058 - loss: 0.3471 - val_accuracy: 0.9166 - val_loss: 0.3226 - learning_rate: 4.0500e-04\n",
      "Epoch 31/150\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9047 - loss: 0.3438 - val_accuracy: 0.9141 - val_loss: 0.3256 - learning_rate: 3.6450e-04\n",
      "Epoch 32/150\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9047 - loss: 0.3444 - val_accuracy: 0.9153 - val_loss: 0.3200 - learning_rate: 3.6450e-04\n",
      "Epoch 33/150\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9050 - loss: 0.3402 - val_accuracy: 0.9149 - val_loss: 0.3219 - learning_rate: 3.6450e-04\n",
      "Epoch 34/150\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9077 - loss: 0.3395 - val_accuracy: 0.9172 - val_loss: 0.3191 - learning_rate: 3.6450e-04\n",
      "Epoch 35/150\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9064 - loss: 0.3365 - val_accuracy: 0.9156 - val_loss: 0.3214 - learning_rate: 3.6450e-04\n",
      "Epoch 36/150\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9080 - loss: 0.3357 - val_accuracy: 0.9157 - val_loss: 0.3194 - learning_rate: 3.6450e-04\n",
      "Epoch 37/150\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9070 - loss: 0.3326 - val_accuracy: 0.9143 - val_loss: 0.3240 - learning_rate: 3.6450e-04\n",
      "Epoch 38/150\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9098 - loss: 0.3294 - val_accuracy: 0.9167 - val_loss: 0.3185 - learning_rate: 3.6450e-04\n",
      "Epoch 39/150\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9077 - loss: 0.3329 - val_accuracy: 0.9164 - val_loss: 0.3193 - learning_rate: 3.6450e-04\n",
      "Epoch 40/150\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9093 - loss: 0.3289 - val_accuracy: 0.9168 - val_loss: 0.3192 - learning_rate: 3.6450e-04\n",
      "Epoch 41/150\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9093 - loss: 0.3294 - val_accuracy: 0.9166 - val_loss: 0.3167 - learning_rate: 3.2805e-04\n",
      "Epoch 42/150\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9099 - loss: 0.3253 - val_accuracy: 0.9177 - val_loss: 0.3160 - learning_rate: 3.2805e-04\n",
      "Epoch 43/150\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9103 - loss: 0.3219 - val_accuracy: 0.9168 - val_loss: 0.3159 - learning_rate: 3.2805e-04\n",
      "Epoch 44/150\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9101 - loss: 0.3246 - val_accuracy: 0.9178 - val_loss: 0.3184 - learning_rate: 3.2805e-04\n",
      "Epoch 45/150\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9117 - loss: 0.3257 - val_accuracy: 0.9156 - val_loss: 0.3172 - learning_rate: 3.2805e-04\n",
      "Epoch 46/150\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9106 - loss: 0.3229 - val_accuracy: 0.9168 - val_loss: 0.3174 - learning_rate: 3.2805e-04\n",
      "Epoch 47/150\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9097 - loss: 0.3255 - val_accuracy: 0.9171 - val_loss: 0.3166 - learning_rate: 3.2805e-04\n",
      "Epoch 48/150\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9118 - loss: 0.3222 - val_accuracy: 0.9172 - val_loss: 0.3159 - learning_rate: 3.2805e-04\n",
      "Epoch 49/150\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9094 - loss: 0.3190 - val_accuracy: 0.9166 - val_loss: 0.3133 - learning_rate: 3.2805e-04\n",
      "Epoch 50/150\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9125 - loss: 0.3212 - val_accuracy: 0.9173 - val_loss: 0.3139 - learning_rate: 3.2805e-04\n",
      "Epoch 51/150\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9119 - loss: 0.3197 - val_accuracy: 0.9181 - val_loss: 0.3170 - learning_rate: 2.9525e-04\n",
      "Epoch 52/150\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9103 - loss: 0.3205 - val_accuracy: 0.9180 - val_loss: 0.3151 - learning_rate: 2.9525e-04\n",
      "Epoch 53/150\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9119 - loss: 0.3137 - val_accuracy: 0.9168 - val_loss: 0.3159 - learning_rate: 2.9525e-04\n",
      "Epoch 54/150\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9120 - loss: 0.3157 - val_accuracy: 0.9192 - val_loss: 0.3097 - learning_rate: 2.9525e-04\n",
      "Epoch 55/150\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9144 - loss: 0.3118 - val_accuracy: 0.9170 - val_loss: 0.3135 - learning_rate: 2.9525e-04\n",
      "Epoch 56/150\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9140 - loss: 0.3105 - val_accuracy: 0.9171 - val_loss: 0.3121 - learning_rate: 2.9525e-04\n",
      "Epoch 57/150\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9105 - loss: 0.3164 - val_accuracy: 0.9167 - val_loss: 0.3149 - learning_rate: 2.9525e-04\n",
      "Epoch 58/150\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9148 - loss: 0.3113 - val_accuracy: 0.9168 - val_loss: 0.3114 - learning_rate: 2.9525e-04\n",
      "Epoch 59/150\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9149 - loss: 0.3081 - val_accuracy: 0.9162 - val_loss: 0.3134 - learning_rate: 2.9525e-04\n",
      "Epoch 60/150\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9145 - loss: 0.3083 - val_accuracy: 0.9169 - val_loss: 0.3146 - learning_rate: 2.9525e-04\n",
      "Epoch 61/150\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9143 - loss: 0.3065 - val_accuracy: 0.9185 - val_loss: 0.3108 - learning_rate: 2.6572e-04\n",
      "Epoch 62/150\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9150 - loss: 0.3079 - val_accuracy: 0.9186 - val_loss: 0.3118 - learning_rate: 2.6572e-04\n",
      "Epoch 63/150\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9151 - loss: 0.3031 - val_accuracy: 0.9204 - val_loss: 0.3111 - learning_rate: 2.6572e-04\n",
      "Epoch 64/150\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9178 - loss: 0.3015 - val_accuracy: 0.9182 - val_loss: 0.3126 - learning_rate: 5.3144e-05\n",
      "Epoch 65/150\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9161 - loss: 0.3023 - val_accuracy: 0.9185 - val_loss: 0.3091 - learning_rate: 2.6572e-04\n",
      "Epoch 66/150\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9168 - loss: 0.2992 - val_accuracy: 0.9152 - val_loss: 0.3138 - learning_rate: 2.6572e-04\n",
      "Epoch 67/150\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9139 - loss: 0.3042 - val_accuracy: 0.9169 - val_loss: 0.3103 - learning_rate: 2.6572e-04\n",
      "Epoch 68/150\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9157 - loss: 0.3007 - val_accuracy: 0.9183 - val_loss: 0.3120 - learning_rate: 2.6572e-04\n",
      "Epoch 69/150\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9163 - loss: 0.2975 - val_accuracy: 0.9178 - val_loss: 0.3100 - learning_rate: 2.6572e-04\n",
      "Epoch 70/150\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9164 - loss: 0.2962 - val_accuracy: 0.9157 - val_loss: 0.3102 - learning_rate: 2.6572e-04\n",
      "Epoch 71/150\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9180 - loss: 0.2968 - val_accuracy: 0.9184 - val_loss: 0.3109 - learning_rate: 2.3915e-04\n",
      "Epoch 72/150\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9185 - loss: 0.2956 - val_accuracy: 0.9188 - val_loss: 0.3108 - learning_rate: 2.3915e-04\n",
      "Epoch 73/150\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9174 - loss: 0.2958 - val_accuracy: 0.9193 - val_loss: 0.3085 - learning_rate: 2.3915e-04\n",
      "Epoch 74/150\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9179 - loss: 0.2917 - val_accuracy: 0.9171 - val_loss: 0.3112 - learning_rate: 2.3915e-04\n",
      "Epoch 75/150\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9166 - loss: 0.2919 - val_accuracy: 0.9183 - val_loss: 0.3084 - learning_rate: 2.3915e-04\n",
      "Epoch 76/150\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9185 - loss: 0.2913 - val_accuracy: 0.9191 - val_loss: 0.3072 - learning_rate: 2.3915e-04\n",
      "Epoch 77/150\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9171 - loss: 0.2921 - val_accuracy: 0.9182 - val_loss: 0.3086 - learning_rate: 2.3915e-04\n",
      "Epoch 78/150\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9167 - loss: 0.2944 - val_accuracy: 0.9178 - val_loss: 0.3118 - learning_rate: 2.3915e-04\n",
      "Epoch 79/150\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9189 - loss: 0.2891 - val_accuracy: 0.9185 - val_loss: 0.3076 - learning_rate: 2.3915e-04\n",
      "Epoch 80/150\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9201 - loss: 0.2858 - val_accuracy: 0.9184 - val_loss: 0.3118 - learning_rate: 2.3915e-04\n",
      "Epoch 81/150\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9206 - loss: 0.2871 - val_accuracy: 0.9198 - val_loss: 0.3103 - learning_rate: 2.1523e-04\n",
      "Epoch 82/150\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9191 - loss: 0.2860 - val_accuracy: 0.9193 - val_loss: 0.3086 - learning_rate: 2.1523e-04\n",
      "Epoch 83/150\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9204 - loss: 0.2832 - val_accuracy: 0.9189 - val_loss: 0.3058 - learning_rate: 2.1523e-04\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415us/step\n",
      "\n",
      "Neural Network Performance Metrics:\n",
      "Accuracy: 0.9204\n",
      "\n",
      "Sample Predictions (first 5):\n",
      "True: Toterahswelt, Predicted: Gasriese\n",
      "True: Wissenschaftlich, Predicted: Wissenschaftlich\n",
      "True: Eiswelt, Predicted: Eiswelt\n",
      "True: Rohstoffreich, Predicted: Rohstoffreich\n",
      "True: Wüstenplanet, Predicted: Wüstenplanet\n",
      "\n",
      "Neural Network Accuracy: 0.9204\n",
      "\n",
      "Data loaded from test_data/cosmictest.csv.\n",
      "Dataset dimensions: 10000 rows, 10 columns\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 476us/step\n",
      "\n",
      "Submission file created: submission.csv\n",
      "\n",
      "Sample predictions (first 5):\n",
      "Planet ID: 1, Predicted Class: 7 (Eiswelt)\n",
      "Planet ID: 2, Predicted Class: 9 (Hohestrahlung)\n",
      "Planet ID: 3, Predicted Class: 4 (Wissenschaftlich)\n",
      "Planet ID: 4, Predicted Class: 3 (Rohstoffreich)\n",
      "Planet ID: 5, Predicted Class: 9 (Hohestrahlung)\n",
      "\n",
      "Execution completed!\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    print(\"\\nStarting Cosmic Planet Classification with Neural Network...\")\n",
    "\n",
    "    # Load and preprocess training data\n",
    "    train_filepath = 'train/train.csv'\n",
    "    df_train, imputer, scaler, feature_cols, _ = load_and_preprocess_data(train_filepath, is_train=True)\n",
    "\n",
    "    # Prepare features and target\n",
    "    X_train_full = df_train.drop('Prediction', axis=1)\n",
    "    y_train_full = to_categorical(df_train['Prediction'].astype(int), num_classes=10)\n",
    "\n",
    "    # Remove highly correlated features\n",
    "    corr_matrix = X_train_full.corr().abs()\n",
    "    upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "    to_drop = [column for column in upper.columns if any(upper[column] > 0.95)]\n",
    "    X_train_full = X_train_full.drop(to_drop, axis=1)\n",
    "    print(f\"Removed {len(to_drop)} highly correlated features\")\n",
    "\n",
    "    # Split into training and validation sets\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X_train_full, y_train_full, test_size=12000, random_state=42,\n",
    "        stratify=np.argmax(y_train_full, axis=1)\n",
    "    )\n",
    "\n",
    "    # Build and train the neural network model\n",
    "    nn_model = build_deep_model((X_train.shape[1],))\n",
    "    nn_model.fit(\n",
    "        X_train, y_train, epochs=150, batch_size=64, validation_data=(X_val, y_val),\n",
    "        callbacks=[\n",
    "            tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=20, restore_best_weights=True, mode='max'),\n",
    "            tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=10, min_lr=1e-7),\n",
    "            tf.keras.callbacks.LearningRateScheduler(lambda epoch: 0.0005 * (0.9 ** (epoch // 10)))\n",
    "        ],\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    # Evaluate the model on validation data\n",
    "    nn_pred = nn_model.predict(X_val)\n",
    "    nn_accuracy = evaluate_model(y_val, nn_pred, \"Neural Network\")\n",
    "    print(f\"\\nNeural Network Accuracy: {nn_accuracy:.4f}\")\n",
    "\n",
    "    # Generate predictions for test data if available\n",
    "    test_filepath = 'test_data/cosmictest.csv'\n",
    "    if os.path.exists(test_filepath):\n",
    "        df_test, planet_ids = load_and_preprocess_data(\n",
    "            test_filepath, is_train=False, imputer=imputer, scaler=scaler, feature_cols=feature_cols\n",
    "        )\n",
    "        \n",
    "        # Use the same features as in training\n",
    "        common_features = set(df_test.columns).intersection(set(X_train_full.columns))\n",
    "        df_test = df_test[list(common_features)]\n",
    "        \n",
    "        # Generate predictions\n",
    "        nn_test_pred = nn_model.predict(df_test)\n",
    "        predicted_classes = np.argmax(nn_test_pred, axis=1) + 1\n",
    "\n",
    "        # Create submission file\n",
    "        submission_df = pd.DataFrame({'Planet_ID': planet_ids, 'Predicted_Class': predicted_classes})\n",
    "        submission_df.to_csv('submission.csv', index=False)\n",
    "        print(\"\\nSubmission file created: submission.csv\")\n",
    "        print(\"\\nSample predictions (first 5):\")\n",
    "        for idx, pred in enumerate(predicted_classes[:5]):\n",
    "            print(f\"Planet ID: {planet_ids[idx]}, Predicted Class: {pred} ({PLANET_TYPES[pred]})\")\n",
    "    else:\n",
    "        print(f\"\\nWARNING: Test file not found.\")\n",
    "\n",
    "    print(\"\\nExecution completed!\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
